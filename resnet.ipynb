{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bagnol/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.io.matlab import loadmat\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "labels=loadmat(\"./imagelabels.mat\")[\"labels\"]\n",
    "model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=\"DEFAULT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.Dropout(p=0.25),\n",
    "    nn.Linear(in_features=2048, out_features=2048),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=2048, out_features=103),\n",
    ")\n",
    "\n",
    "PATH = './model_dict.pth'\n",
    "if os.path.exists(PATH):\n",
    "    print(\"loading pretrained model\")\n",
    "    model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:\t65 total elements with batch size of 96\n",
      "validation set:\t255 total elements with batch size of 4\n",
      "test set:\t255 total elements with batch size of 4\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "transform=transforms.Compose([transforms.Resize([500,500]),transforms.ToTensor()])\n",
    "dataset_list=[transform(Image.open(os.path.join(\"./jpg\",path))) for path in os.listdir(\"./jpg/\")]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader([(dataset_list[i-1],labels[0][i-1]) for i in loadmat(\"./setid.mat\")[\"trnid\"][0]], batch_size=4)\n",
    "val_loader = torch.utils.data.DataLoader([(dataset_list[i-1],labels[0][i-1]) for i in loadmat(\"./setid.mat\")[\"valid\"][0]], batch_size=4)\n",
    "train_loader = torch.utils.data.DataLoader([(dataset_list[i-1],labels[0][i-1]) for i in loadmat(\"./setid.mat\")[\"tstid\"][0]], batch_size=96, shuffle=True)\n",
    "\n",
    "print(\"train set:\\t\"+str(len(train_loader))+\" total elements with batch size of \"+str(train_loader.batch_size))\n",
    "print(\"validation set:\\t\"+str(len(val_loader))+\" total elements with batch size of \"+str(val_loader.batch_size))\n",
    "print(\"test set:\\t\"+str(len(test_loader))+\" total elements with batch size of \"+str(test_loader.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.fc.parameters(), 'lr': 5e-3}\n",
    "        ]\n",
    "optimizer_ft = optim.Adam(plist, lr=0.001)\n",
    "lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(plist, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    tqdm_data=tqdm(enumerate(train_loader, 0),desc=\"epoch \"+str(epoch+1),total=len(train_loader),leave=False)\n",
    "    for i, data in tqdm_data:\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0], data[1]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer_ft.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_ft.step()\n",
    "\n",
    "        tqdm_data.set_postfix(loss= loss.item(), refresh=False)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    lr_sch.step()\n",
    "torch.save(model.state_dict(), PATH)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [03:03<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import torchvision\n",
    "\n",
    "model.eval()\n",
    "it=iter(val_loader)\n",
    "pred=list()\n",
    "true_labels=list()\n",
    "class_accuracy={str(i+1):{\"true\":0, \"total\":0} for i in range(102)}\n",
    "accuracy=0\n",
    "for i, data in tqdm(enumerate(val_loader, 0),total=len(val_loader)):\n",
    "    val_images, val_labels = data[0], data[1]\n",
    "\n",
    "    #imshow(torchvision.utils.make_grid(val_images).permute(1,2,0))\n",
    "    #print('GroundTruth: ', ' '.join(f'{str(val_labels[j].item()):5s}' for j in range(4)))\n",
    "    outputs = model(val_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    #print('Predicted: ', ' '.join(f'{str(predicted[j].item()):5s}' for j in range(4)))\n",
    "    for b in range(4):\n",
    "        if val_labels[b].item()==predicted[b].item():\n",
    "            accuracy+=1\n",
    "            class_accuracy[str(val_labels[b].item())][\"true\"]+=1\n",
    "        class_accuracy[str(val_labels[b].item())][\"total\"]+=1\n",
    "        true_labels.append(val_labels[b].item())\n",
    "        pred.append(predicted[b].item())\n",
    "accuracy=accuracy/(4*len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.013725490196078431\n",
      "\n",
      "Classes accuracy:\t{'1': {'true': 0, 'total': 10}, '2': {'true': 0, 'total': 10}, '3': {'true': 0, 'total': 10}, '4': {'true': 0, 'total': 10}, '5': {'true': 0, 'total': 10}, '6': {'true': 0, 'total': 10}, '7': {'true': 0, 'total': 10}, '8': {'true': 0, 'total': 10}, '9': {'true': 0, 'total': 10}, '10': {'true': 0, 'total': 10}, '11': {'true': 0, 'total': 10}, '12': {'true': 0, 'total': 10}, '13': {'true': 0, 'total': 10}, '14': {'true': 0, 'total': 10}, '15': {'true': 0, 'total': 10}, '16': {'true': 0, 'total': 10}, '17': {'true': 0, 'total': 10}, '18': {'true': 0, 'total': 10}, '19': {'true': 0, 'total': 10}, '20': {'true': 0, 'total': 10}, '21': {'true': 0, 'total': 10}, '22': {'true': 0, 'total': 10}, '23': {'true': 0, 'total': 10}, '24': {'true': 0, 'total': 10}, '25': {'true': 0, 'total': 10}, '26': {'true': 0, 'total': 10}, '27': {'true': 0, 'total': 10}, '28': {'true': 0, 'total': 10}, '29': {'true': 0, 'total': 10}, '30': {'true': 0, 'total': 10}, '31': {'true': 0, 'total': 10}, '32': {'true': 0, 'total': 10}, '33': {'true': 0, 'total': 10}, '34': {'true': 0, 'total': 10}, '35': {'true': 0, 'total': 10}, '36': {'true': 0, 'total': 10}, '37': {'true': 0, 'total': 10}, '38': {'true': 0, 'total': 10}, '39': {'true': 0, 'total': 10}, '40': {'true': 0, 'total': 10}, '41': {'true': 0, 'total': 10}, '42': {'true': 0, 'total': 10}, '43': {'true': 0, 'total': 10}, '44': {'true': 0, 'total': 10}, '45': {'true': 0, 'total': 10}, '46': {'true': 0, 'total': 10}, '47': {'true': 0, 'total': 10}, '48': {'true': 0, 'total': 10}, '49': {'true': 0, 'total': 10}, '50': {'true': 0, 'total': 10}, '51': {'true': 0, 'total': 10}, '52': {'true': 0, 'total': 10}, '53': {'true': 0, 'total': 10}, '54': {'true': 0, 'total': 10}, '55': {'true': 0, 'total': 10}, '56': {'true': 0, 'total': 10}, '57': {'true': 0, 'total': 10}, '58': {'true': 0, 'total': 10}, '59': {'true': 0, 'total': 10}, '60': {'true': 0, 'total': 10}, '61': {'true': 0, 'total': 10}, '62': {'true': 0, 'total': 10}, '63': {'true': 0, 'total': 10}, '64': {'true': 0, 'total': 10}, '65': {'true': 0, 'total': 10}, '66': {'true': 0, 'total': 10}, '67': {'true': 0, 'total': 10}, '68': {'true': 0, 'total': 10}, '69': {'true': 0, 'total': 10}, '70': {'true': 0, 'total': 10}, '71': {'true': 0, 'total': 10}, '72': {'true': 0, 'total': 10}, '73': {'true': 0, 'total': 10}, '74': {'true': 0, 'total': 10}, '75': {'true': 0, 'total': 10}, '76': {'true': 0, 'total': 10}, '77': {'true': 1, 'total': 10}, '78': {'true': 0, 'total': 10}, '79': {'true': 0, 'total': 10}, '80': {'true': 0, 'total': 10}, '81': {'true': 1, 'total': 10}, '82': {'true': 0, 'total': 10}, '83': {'true': 0, 'total': 10}, '84': {'true': 0, 'total': 10}, '85': {'true': 0, 'total': 10}, '86': {'true': 0, 'total': 10}, '87': {'true': 0, 'total': 10}, '88': {'true': 5, 'total': 10}, '89': {'true': 6, 'total': 10}, '90': {'true': 0, 'total': 10}, '91': {'true': 0, 'total': 10}, '92': {'true': 0, 'total': 10}, '93': {'true': 0, 'total': 10}, '94': {'true': 1, 'total': 10}, '95': {'true': 0, 'total': 10}, '96': {'true': 0, 'total': 10}, '97': {'true': 0, 'total': 10}, '98': {'true': 0, 'total': 10}, '99': {'true': 0, 'total': 10}, '100': {'true': 0, 'total': 10}, '101': {'true': 0, 'total': 10}, '102': {'true': 0, 'total': 10}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\\t\"+str(accuracy))\n",
    "print(f\"\\nClasses accuracy:\\t{class_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
